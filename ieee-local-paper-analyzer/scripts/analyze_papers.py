#!/usr/bin/env python3
import argparse
import json
import re
from collections import Counter
from pathlib import Path

STOPWORDS = {
    "the", "a", "an", "and", "or", "to", "of", "in", "for", "on", "with", "by", "from", "at",
    "using", "based", "via", "towards", "toward", "through", "study", "analysis", "method", "methods",
    "ieee", "paper", "approach", "model", "models", "system", "systems",
}


def load_jsonl(path: Path) -> list[dict]:
    rows = []
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            rows.append(json.loads(line))
    return rows


def tokenize(text: str) -> list[str]:
    tokens = re.findall(r"[a-zA-Z][a-zA-Z0-9\-]{2,}", text.lower())
    return [t for t in tokens if t not in STOPWORDS]


def build_report(rows: list[dict], top_k: int, min_year: int | None) -> str:
    if min_year:
        rows = [r for r in rows if isinstance(r.get("year"), int) and r["year"] >= min_year]

    total = len(rows)
    year_counter = Counter()
    term_counter = Counter()
    keyword_counter = Counter()
    author_counter = Counter()
    venue_counter = Counter()

    exemplar_by_term: dict[str, dict] = {}

    for row in rows:
        year = row.get("year")
        if isinstance(year, int):
            year_counter[year] += 1

        for a in row.get("authors", []):
            if a:
                author_counter[a] += 1

        venue = row.get("publication_title") or ""
        if venue:
            venue_counter[venue] += 1

        for kw in row.get("keywords", []):
            kw = kw.strip().lower()
            if kw:
                keyword_counter[kw] += 1

        text = f"{row.get('title', '')} {row.get('abstract', '')}"
        terms = tokenize(text)
        local_counter = Counter(terms)
        term_counter.update(local_counter)

        for t, _ in local_counter.most_common(5):
            if t not in exemplar_by_term:
                exemplar_by_term[t] = row

    lines = []
    lines.append("# IEEE 论文集合汇总分析")
    lines.append("")
    lines.append(f"- 样本量: **{total}**")
    lines.append(f"- 年份跨度: **{min(year_counter) if year_counter else 'N/A'} ~ {max(year_counter) if year_counter else 'N/A'}**")
    lines.append("")

    lines.append("## 年份分布")
    for y, c in sorted(year_counter.items()):
        lines.append(f"- {y}: {c}")
    lines.append("")

    lines.append("## 高频术语（标题+摘要）")
    for term, c in term_counter.most_common(top_k):
        lines.append(f"- {term}: {c}")
    lines.append("")

    lines.append("## 高频关键词（metadata）")
    for kw, c in keyword_counter.most_common(top_k):
        lines.append(f"- {kw}: {c}")
    lines.append("")

    lines.append("## 主要作者")
    for author, c in author_counter.most_common(top_k):
        lines.append(f"- {author}: {c}")
    lines.append("")

    lines.append("## 主要期刊/会议")
    for venue, c in venue_counter.most_common(top_k):
        lines.append(f"- {venue}: {c}")
    lines.append("")

    lines.append("## 代表论文（按高频术语映射）")
    selected = set()
    for term, _ in term_counter.most_common(top_k):
        row = exemplar_by_term.get(term)
        if not row:
            continue
        title = row.get("title") or "(untitled)"
        if title in selected:
            continue
        selected.add(title)
        lines.append(f"- **{title}** ({row.get('year', 'N/A')})")
        lines.append(f"  - term: `{term}`")
        if row.get("doi"):
            lines.append(f"  - doi: {row['doi']}")
        if row.get("document_url"):
            lines.append(f"  - link: {row['document_url']}")

    lines.append("")
    lines.append("## 结论建议")
    lines.append("- 可先按高频关键词聚焦 2~3 个子主题，再做二次定向抓取。")
    lines.append("- 对高频作者与 venue 做交叉筛选，可快速定位核心文献群。")
    lines.append("- 若摘要缺失率高，建议补抓详情页后再做深度总结。")

    return "\n".join(lines)


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Analyze crawled IEEE paper metadata and generate a markdown report.")
    p.add_argument("--input", required=True, help="Input JSONL generated by crawl_ieee.py")
    p.add_argument("--top-k", type=int, default=12, help="Top K items for stats sections")
    p.add_argument("--min-year", type=int, default=None, help="Only include papers with year >= this value")
    p.add_argument("--report-out", required=True, help="Output markdown report path")
    return p.parse_args()


def main() -> None:
    args = parse_args()
    rows = load_jsonl(Path(args.input))
    report = build_report(rows, top_k=args.top_k, min_year=args.min_year)

    out = Path(args.report_out)
    out.parent.mkdir(parents=True, exist_ok=True)
    out.write_text(report, encoding="utf-8")
    print(f"Analyzed {len(rows)} papers -> {out}")


if __name__ == "__main__":
    main()
